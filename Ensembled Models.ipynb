{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 100 audio files in the dataset.\n",
      "Preview of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Story_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001.wav</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00002.wav</th>\n",
       "      <td>English</td>\n",
       "      <td>true_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00003.wav</th>\n",
       "      <td>English</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00004.wav</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00005.wav</th>\n",
       "      <td>English</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Language       Story_type\n",
       "filename                           \n",
       "00001.wav    Hindi  deceptive_story\n",
       "00002.wav  English       true_story\n",
       "00003.wav  English  deceptive_story\n",
       "00004.wav  Bengali  deceptive_story\n",
       "00005.wav  English  deceptive_story"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the base directory\n",
    "base_path = './MLEnd/deception/MLEndDD_stories_small/'\n",
    "\n",
    "# Load the CSV file and ensure labels are accessible\n",
    "MLEND_df = pd.read_csv('./MLEnd/deception/MLEndDD_story_attributes_small.csv').set_index('filename')\n",
    "\n",
    "# Create a list of full file paths using the CSV index\n",
    "files = [base_path + file for file in MLEND_df.index]\n",
    "\n",
    "# Check the number of files and preview the dataset\n",
    "print(f\"We have {len(files)} audio files in the dataset.\")\n",
    "print(\"Preview of the dataset:\")\n",
    "display(MLEND_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid audio chunks created: 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def split_audio_into_chunks(file_id, file_path, label, chunk_duration=30, sr=None):\n",
    "    \"\"\"\n",
    "    Splits an audio file into 30-second chunks and discards chunks shorter than 30 seconds.\n",
    "\n",
    "    Args:\n",
    "        file_id (str): The file ID (original file name).\n",
    "        file_path (str): Path to the audio file.\n",
    "        label (str): Label for the audio file (e.g., 'true_story' or 'deceptive_story').\n",
    "        chunk_duration (int): Duration of each chunk in seconds (default: 30).\n",
    "        sr (int or None): Sampling rate. If None, uses the original rate.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples [(chunk, label, file_id)].\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=sr)  # Load audio\n",
    "    chunk_size = chunk_duration * sr       # Calculate chunk size in samples\n",
    "    chunks = [y[i:i + int(chunk_size)] for i in range(0, len(y), int(chunk_size))]\n",
    "\n",
    "    # Discard chunks shorter than the desired length\n",
    "    valid_chunks = [chunk for chunk in chunks if len(chunk) == chunk_size]\n",
    "\n",
    "    # Return a list of (chunk, label, file_id)\n",
    "    return [(chunk, label, file_id) for chunk in valid_chunks]\n",
    "\n",
    "# Iterate over all files and split them into chunks\n",
    "audio_chunks = []\n",
    "for file_id in tqdm(MLEND_df.index):  # Iterate over file IDs in the CSV\n",
    "    file_path = base_path + file_id   # Construct full file path\n",
    "    label = MLEND_df.loc[file_id, 'Story_type']  # Retrieve label from the CSV\n",
    "    audio_chunks.extend(split_audio_into_chunks(file_id, file_path, label))\n",
    "\n",
    "# Output the total number of valid chunks\n",
    "print(f\"Total valid audio chunks created: {len(audio_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Audio Files:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Number of Chunks</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.wav</td>\n",
       "      <td>122.167256</td>\n",
       "      <td>4</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.wav</td>\n",
       "      <td>125.192018</td>\n",
       "      <td>4</td>\n",
       "      <td>true_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.wav</td>\n",
       "      <td>162.984127</td>\n",
       "      <td>5</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.wav</td>\n",
       "      <td>121.681270</td>\n",
       "      <td>4</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.wav</td>\n",
       "      <td>134.189751</td>\n",
       "      <td>4</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>00096.wav</td>\n",
       "      <td>111.512063</td>\n",
       "      <td>3</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>00097.wav</td>\n",
       "      <td>185.731224</td>\n",
       "      <td>6</td>\n",
       "      <td>true_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>00098.wav</td>\n",
       "      <td>128.252766</td>\n",
       "      <td>4</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>00099.wav</td>\n",
       "      <td>132.412562</td>\n",
       "      <td>4</td>\n",
       "      <td>true_story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>00100.wav</td>\n",
       "      <td>123.273560</td>\n",
       "      <td>4</td>\n",
       "      <td>deceptive_story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      File ID  Duration (s)  Number of Chunks            Label\n",
       "0   00001.wav    122.167256                 4  deceptive_story\n",
       "1   00002.wav    125.192018                 4       true_story\n",
       "2   00003.wav    162.984127                 5  deceptive_story\n",
       "3   00004.wav    121.681270                 4  deceptive_story\n",
       "4   00005.wav    134.189751                 4  deceptive_story\n",
       "..        ...           ...               ...              ...\n",
       "95  00096.wav    111.512063                 3  deceptive_story\n",
       "96  00097.wav    185.731224                 6       true_story\n",
       "97  00098.wav    128.252766                 4  deceptive_story\n",
       "98  00099.wav    132.412562                 4       true_story\n",
       "99  00100.wav    123.273560                 4  deceptive_story\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Audio Chunks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>File ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.wav_chunk1</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.wav_chunk2</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001.wav_chunk3</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001.wav_chunk4</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002.wav_chunk1</td>\n",
       "      <td>true_story</td>\n",
       "      <td>00002.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>00099.wav_chunk4</td>\n",
       "      <td>true_story</td>\n",
       "      <td>00099.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>00100.wav_chunk1</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00100.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>00100.wav_chunk2</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00100.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>00100.wav_chunk3</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00100.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>00100.wav_chunk4</td>\n",
       "      <td>deceptive_story</td>\n",
       "      <td>00100.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Chunk ID            Label    File ID\n",
       "0    00001.wav_chunk1  deceptive_story  00001.wav\n",
       "1    00001.wav_chunk2  deceptive_story  00001.wav\n",
       "2    00001.wav_chunk3  deceptive_story  00001.wav\n",
       "3    00001.wav_chunk4  deceptive_story  00001.wav\n",
       "4    00002.wav_chunk1       true_story  00002.wav\n",
       "..                ...              ...        ...\n",
       "415  00099.wav_chunk4       true_story  00099.wav\n",
       "416  00100.wav_chunk1  deceptive_story  00100.wav\n",
       "417  00100.wav_chunk2  deceptive_story  00100.wav\n",
       "418  00100.wav_chunk3  deceptive_story  00100.wav\n",
       "419  00100.wav_chunk4  deceptive_story  00100.wav\n",
       "\n",
       "[420 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid audio chunks created: 420\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_audio_into_chunks(file_id, file_path, label, chunk_duration=30, sr=None):\n",
    "    \"\"\"\n",
    "    Splits an audio file into 30-second chunks and discards chunks shorter than 30 seconds.\n",
    "\n",
    "    Args:\n",
    "        file_id (str): The file ID (original file name).\n",
    "        file_path (str): Path to the audio file.\n",
    "        label (str): Label for the audio file (e.g., 'true_story' or 'deceptive_story').\n",
    "        chunk_duration (int): Duration of each chunk in seconds (default: 30).\n",
    "        sr (int or None): Sampling rate. If None, uses the original rate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: File metadata (duration, number of valid chunks, label) and a list of chunk data with IDs.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=sr)  # Load audio\n",
    "    duration = len(y) / sr  # Calculate total duration in seconds\n",
    "    chunk_size = chunk_duration * sr       # Calculate chunk size in samples\n",
    "    chunks = [y[i:i + int(chunk_size)] for i in range(0, len(y), int(chunk_size))]\n",
    "\n",
    "    # Discard chunks shorter than the desired length\n",
    "    valid_chunks = [chunk for chunk in chunks if len(chunk) == chunk_size]\n",
    "\n",
    "    # Prepare metadata and chunks with Chunk ID\n",
    "    metadata = {\"File ID\": file_id, \"Duration (s)\": duration, \"Number of Chunks\": len(valid_chunks), \"Label\": label}\n",
    "    chunk_data = [(f\"{file_id}_chunk{i+1}\", chunk, label, file_id) for i, chunk in enumerate(valid_chunks)]\n",
    "    \n",
    "    return metadata, chunk_data\n",
    "\n",
    "# Initialize lists for metadata and chunks\n",
    "file_metadata = []\n",
    "audio_chunks = []\n",
    "\n",
    "# Iterate over all files and process\n",
    "for file_id in tqdm(MLEND_df.index):  # Iterate over file IDs in the CSV\n",
    "    file_path = base_path + file_id   # Construct full file path\n",
    "    label = MLEND_df.loc[file_id, 'Story_type']  # Retrieve label from the CSV\n",
    "\n",
    "    # Split into chunks and collect metadata\n",
    "    metadata, chunks = split_audio_into_chunks(file_id, file_path, label)\n",
    "    file_metadata.append(metadata)  # Collect metadata for the file\n",
    "    audio_chunks.extend(chunks)     # Collect valid chunks\n",
    "\n",
    "# Convert metadata to a DataFrame for easy viewing\n",
    "metadata_df = pd.DataFrame(file_metadata)\n",
    "\n",
    "# Display metadata\n",
    "print(\"Summary of Audio Files:\")\n",
    "display(metadata_df)\n",
    "\n",
    "# Prepare a DataFrame for audio chunks\n",
    "chunks_df = pd.DataFrame(audio_chunks, columns=[\"Chunk ID\", \"Chunk Data\", \"Label\", \"File ID\"])\n",
    "\n",
    "# Display chunk summary\n",
    "print(\"Summary of Audio Chunks:\")\n",
    "display(chunks_df[[\"Chunk ID\", \"Label\", \"File ID\"]])\n",
    "\n",
    "# Output the total number of valid chunks\n",
    "print(f\"Total valid audio chunks created: {len(audio_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('00001.wav_chunk1',\n",
       " array([1.5258789e-05, 1.5258789e-05, 3.0517578e-05, ..., 2.8564453e-02,\n",
       "        2.8488159e-02, 2.8121948e-02], dtype=float32),\n",
       " 'deceptive_story',\n",
       " '00001.wav')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_chunks[0]     #[(f\"{file_id}_chunk{i+1}\", chunk, label, file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution in Chunks:\n",
      "deceptive_story: 201 chunks\n",
      "true_story: 219 chunks\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Extract labels from the chunks\n",
    "chunk_labels = [chunk[2] for chunk in audio_chunks]  # Extract the 'label' field from the tuples\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(chunk_labels)\n",
    "\n",
    "# Display the label distribution\n",
    "print(\"Label Distribution in Chunks:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count} chunks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show each recording has how many chunks and their corresponding label\n",
    "\n",
    "- code required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your dataset has the following label distribution:\n",
    "\n",
    "True Stories: 219 chunks.\n",
    "Deceptive Stories: 201 chunks.\n",
    "This results in the following proportions:\n",
    "\n",
    "True Stories: \n",
    "219\n",
    "420\n",
    "≈\n",
    "52.14\n",
    "%\n",
    "420\n",
    "219\n",
    "​\n",
    " ≈52.14%\n",
    "Deceptive Stories: \n",
    "201\n",
    "420\n",
    "≈\n",
    "47.86\n",
    "%\n",
    "420\n",
    "201\n",
    "​\n",
    " ≈47.86%\n",
    "Is This Balanced?\n",
    "In machine learning, a dataset is generally considered balanced if:\n",
    "\n",
    "The class proportions are roughly equal (e.g., both classes are close to 50% in binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features_and_labels(audio_chunks, sr=16000, scale_audio=True):\n",
    "    \"\"\"\n",
    "    Extract features (MFCC, Pitch, Energy, ZCR) and associate labels for 30-second audio chunks.\n",
    "\n",
    "    Args:\n",
    "        audio_chunks (list): List of tuples [(chunk, label, file_id)].\n",
    "        n_mfcc (int): Number of MFCC coefficients to extract.\n",
    "        sr (int): Sampling rate for feature extraction.\n",
    "        scale_audio (bool): Whether to scale audio amplitude.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Feature matrix (X) with extracted features for each chunk.\n",
    "        np.ndarray: Label vector (y) corresponding to each chunk.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    for chunk_id, chunk, label, file_id in tqdm(audio_chunks):\n",
    "        # Scale the audio if required\n",
    "        if scale_audio:\n",
    "            chunk = chunk / np.max(np.abs(chunk)) if np.max(np.abs(chunk)) > 0 else chunk\n",
    "\n",
    "        # Extract MFCC features\n",
    "        n_mfcc =13\n",
    "        mfcc = librosa.feature.mfcc(y=chunk, sr=sr, n_mfcc=n_mfcc).mean(axis=1)\n",
    "\n",
    "        # Extract Pitch features\n",
    "        pitch, _, _ = librosa.pyin(chunk, fmin=80, fmax=450, sr=sr)\n",
    "        pitch_mean = np.nanmean(pitch) if np.mean(np.isnan(pitch)) < 1 else 0\n",
    "        pitch_std = np.nanstd(pitch) if np.mean(np.isnan(pitch)) < 1 else 0\n",
    "\n",
    "        # Compute Energy (RMS)\n",
    "        rms = np.mean(librosa.feature.rms(y=chunk))\n",
    "\n",
    "        # Compute Zero-Crossing Rate (ZCR)\n",
    "        zcr = np.mean(librosa.feature.zero_crossing_rate(y=chunk))\n",
    "\n",
    "        # Combine all features into a single feature vector\n",
    "        xi = np.concatenate([mfcc, [pitch_mean, pitch_std, rms, zcr]])\n",
    "        X.append(xi)\n",
    "\n",
    "        # Append the corresponding label\n",
    "        y.append(1 if label == 'true_story' else 0)  # Binary encode labels\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [12:30<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (420, 17)\n",
      "Label vector shape: (420,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure feature extraction is performed\n",
    "X, y = extract_features_and_labels(audio_chunks, sr=16000, scale_audio=True)\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Label vector shape: {y.shape}\")\n",
    "\n",
    "#12.30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the extracted features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCC_1</th>\n",
       "      <th>MFCC_2</th>\n",
       "      <th>MFCC_3</th>\n",
       "      <th>MFCC_4</th>\n",
       "      <th>MFCC_5</th>\n",
       "      <th>MFCC_6</th>\n",
       "      <th>MFCC_7</th>\n",
       "      <th>MFCC_8</th>\n",
       "      <th>MFCC_9</th>\n",
       "      <th>MFCC_10</th>\n",
       "      <th>MFCC_11</th>\n",
       "      <th>MFCC_12</th>\n",
       "      <th>MFCC_13</th>\n",
       "      <th>Pitch_Mean</th>\n",
       "      <th>Pitch_Std</th>\n",
       "      <th>RMS</th>\n",
       "      <th>ZCR</th>\n",
       "      <th>Label</th>\n",
       "      <th>File_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-397.277435</td>\n",
       "      <td>115.308823</td>\n",
       "      <td>26.619108</td>\n",
       "      <td>4.842953</td>\n",
       "      <td>15.125876</td>\n",
       "      <td>13.251455</td>\n",
       "      <td>8.787902</td>\n",
       "      <td>7.114931</td>\n",
       "      <td>5.688897</td>\n",
       "      <td>3.441538</td>\n",
       "      <td>-0.148061</td>\n",
       "      <td>4.820008</td>\n",
       "      <td>14.553017</td>\n",
       "      <td>89.916438</td>\n",
       "      <td>11.904371</td>\n",
       "      <td>0.067561</td>\n",
       "      <td>0.052729</td>\n",
       "      <td>0</td>\n",
       "      <td>00001.wav_chunk1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-341.413879</td>\n",
       "      <td>112.532097</td>\n",
       "      <td>26.875120</td>\n",
       "      <td>3.859308</td>\n",
       "      <td>10.727917</td>\n",
       "      <td>9.089574</td>\n",
       "      <td>8.194948</td>\n",
       "      <td>8.354401</td>\n",
       "      <td>6.138742</td>\n",
       "      <td>3.457012</td>\n",
       "      <td>0.086589</td>\n",
       "      <td>4.308666</td>\n",
       "      <td>13.157206</td>\n",
       "      <td>100.921285</td>\n",
       "      <td>57.813181</td>\n",
       "      <td>0.097667</td>\n",
       "      <td>0.055318</td>\n",
       "      <td>0</td>\n",
       "      <td>00001.wav_chunk2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-355.009125</td>\n",
       "      <td>119.337051</td>\n",
       "      <td>24.410446</td>\n",
       "      <td>6.237376</td>\n",
       "      <td>14.495246</td>\n",
       "      <td>9.676167</td>\n",
       "      <td>8.971926</td>\n",
       "      <td>7.552096</td>\n",
       "      <td>3.964255</td>\n",
       "      <td>3.650847</td>\n",
       "      <td>0.749403</td>\n",
       "      <td>4.240197</td>\n",
       "      <td>13.814740</td>\n",
       "      <td>100.859701</td>\n",
       "      <td>53.138592</td>\n",
       "      <td>0.105106</td>\n",
       "      <td>0.058541</td>\n",
       "      <td>0</td>\n",
       "      <td>00001.wav_chunk3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-388.253235</td>\n",
       "      <td>116.238152</td>\n",
       "      <td>26.251518</td>\n",
       "      <td>5.487333</td>\n",
       "      <td>13.262886</td>\n",
       "      <td>9.602457</td>\n",
       "      <td>6.639931</td>\n",
       "      <td>5.021115</td>\n",
       "      <td>4.648613</td>\n",
       "      <td>5.378964</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>3.370997</td>\n",
       "      <td>13.841707</td>\n",
       "      <td>98.482368</td>\n",
       "      <td>38.953589</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.051922</td>\n",
       "      <td>0</td>\n",
       "      <td>00001.wav_chunk4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-341.225281</td>\n",
       "      <td>118.129440</td>\n",
       "      <td>21.087967</td>\n",
       "      <td>23.655165</td>\n",
       "      <td>2.626698</td>\n",
       "      <td>27.793694</td>\n",
       "      <td>16.048880</td>\n",
       "      <td>7.064847</td>\n",
       "      <td>5.248309</td>\n",
       "      <td>-0.175199</td>\n",
       "      <td>13.492320</td>\n",
       "      <td>5.195230</td>\n",
       "      <td>-5.622330</td>\n",
       "      <td>131.835363</td>\n",
       "      <td>69.975678</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.069831</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.wav_chunk1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-352.747955</td>\n",
       "      <td>123.446228</td>\n",
       "      <td>22.154636</td>\n",
       "      <td>22.628866</td>\n",
       "      <td>3.410473</td>\n",
       "      <td>31.359163</td>\n",
       "      <td>17.365978</td>\n",
       "      <td>5.906202</td>\n",
       "      <td>3.478702</td>\n",
       "      <td>-0.525651</td>\n",
       "      <td>12.964216</td>\n",
       "      <td>3.917714</td>\n",
       "      <td>-7.604085</td>\n",
       "      <td>113.318635</td>\n",
       "      <td>52.484190</td>\n",
       "      <td>0.052430</td>\n",
       "      <td>0.067662</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.wav_chunk2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-335.256531</td>\n",
       "      <td>114.930779</td>\n",
       "      <td>21.377239</td>\n",
       "      <td>21.028791</td>\n",
       "      <td>7.294496</td>\n",
       "      <td>27.854549</td>\n",
       "      <td>18.035589</td>\n",
       "      <td>6.776508</td>\n",
       "      <td>3.678071</td>\n",
       "      <td>1.138009</td>\n",
       "      <td>12.520448</td>\n",
       "      <td>1.734315</td>\n",
       "      <td>-6.671849</td>\n",
       "      <td>119.723847</td>\n",
       "      <td>61.242451</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.wav_chunk3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-321.387543</td>\n",
       "      <td>120.846916</td>\n",
       "      <td>23.287342</td>\n",
       "      <td>22.254333</td>\n",
       "      <td>4.051879</td>\n",
       "      <td>27.580341</td>\n",
       "      <td>17.535589</td>\n",
       "      <td>7.562186</td>\n",
       "      <td>5.637784</td>\n",
       "      <td>2.195768</td>\n",
       "      <td>14.759595</td>\n",
       "      <td>1.976602</td>\n",
       "      <td>-8.822467</td>\n",
       "      <td>116.887366</td>\n",
       "      <td>53.195553</td>\n",
       "      <td>0.068936</td>\n",
       "      <td>0.061652</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.wav_chunk4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-342.061371</td>\n",
       "      <td>119.052788</td>\n",
       "      <td>33.504265</td>\n",
       "      <td>10.626637</td>\n",
       "      <td>22.607630</td>\n",
       "      <td>32.303413</td>\n",
       "      <td>15.722194</td>\n",
       "      <td>8.065565</td>\n",
       "      <td>-1.798357</td>\n",
       "      <td>-2.873680</td>\n",
       "      <td>-4.494293</td>\n",
       "      <td>-7.010339</td>\n",
       "      <td>-7.906294</td>\n",
       "      <td>84.149052</td>\n",
       "      <td>7.553484</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>0.060897</td>\n",
       "      <td>0</td>\n",
       "      <td>00003.wav_chunk1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-332.177429</td>\n",
       "      <td>119.742607</td>\n",
       "      <td>34.443279</td>\n",
       "      <td>15.258172</td>\n",
       "      <td>22.072105</td>\n",
       "      <td>27.921467</td>\n",
       "      <td>14.051162</td>\n",
       "      <td>8.111733</td>\n",
       "      <td>-1.800246</td>\n",
       "      <td>-6.144019</td>\n",
       "      <td>-1.627588</td>\n",
       "      <td>-4.922258</td>\n",
       "      <td>-10.025845</td>\n",
       "      <td>111.379344</td>\n",
       "      <td>81.207328</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.065956</td>\n",
       "      <td>0</td>\n",
       "      <td>00003.wav_chunk2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MFCC_1      MFCC_2     MFCC_3     MFCC_4     MFCC_5     MFCC_6  \\\n",
       "0 -397.277435  115.308823  26.619108   4.842953  15.125876  13.251455   \n",
       "1 -341.413879  112.532097  26.875120   3.859308  10.727917   9.089574   \n",
       "2 -355.009125  119.337051  24.410446   6.237376  14.495246   9.676167   \n",
       "3 -388.253235  116.238152  26.251518   5.487333  13.262886   9.602457   \n",
       "4 -341.225281  118.129440  21.087967  23.655165   2.626698  27.793694   \n",
       "5 -352.747955  123.446228  22.154636  22.628866   3.410473  31.359163   \n",
       "6 -335.256531  114.930779  21.377239  21.028791   7.294496  27.854549   \n",
       "7 -321.387543  120.846916  23.287342  22.254333   4.051879  27.580341   \n",
       "8 -342.061371  119.052788  33.504265  10.626637  22.607630  32.303413   \n",
       "9 -332.177429  119.742607  34.443279  15.258172  22.072105  27.921467   \n",
       "\n",
       "      MFCC_7    MFCC_8    MFCC_9   MFCC_10    MFCC_11   MFCC_12    MFCC_13  \\\n",
       "0   8.787902  7.114931  5.688897  3.441538  -0.148061  4.820008  14.553017   \n",
       "1   8.194948  8.354401  6.138742  3.457012   0.086589  4.308666  13.157206   \n",
       "2   8.971926  7.552096  3.964255  3.650847   0.749403  4.240197  13.814740   \n",
       "3   6.639931  5.021115  4.648613  5.378964   0.879893  3.370997  13.841707   \n",
       "4  16.048880  7.064847  5.248309 -0.175199  13.492320  5.195230  -5.622330   \n",
       "5  17.365978  5.906202  3.478702 -0.525651  12.964216  3.917714  -7.604085   \n",
       "6  18.035589  6.776508  3.678071  1.138009  12.520448  1.734315  -6.671849   \n",
       "7  17.535589  7.562186  5.637784  2.195768  14.759595  1.976602  -8.822467   \n",
       "8  15.722194  8.065565 -1.798357 -2.873680  -4.494293 -7.010339  -7.906294   \n",
       "9  14.051162  8.111733 -1.800246 -6.144019  -1.627588 -4.922258 -10.025845   \n",
       "\n",
       "   Pitch_Mean  Pitch_Std       RMS       ZCR  Label           File_ID  \n",
       "0   89.916438  11.904371  0.067561  0.052729      0  00001.wav_chunk1  \n",
       "1  100.921285  57.813181  0.097667  0.055318      0  00001.wav_chunk2  \n",
       "2  100.859701  53.138592  0.105106  0.058541      0  00001.wav_chunk3  \n",
       "3   98.482368  38.953589  0.066512  0.051922      0  00001.wav_chunk4  \n",
       "4  131.835363  69.975678  0.052946  0.069831      1  00002.wav_chunk1  \n",
       "5  113.318635  52.484190  0.052430  0.067662      1  00002.wav_chunk2  \n",
       "6  119.723847  61.242451  0.057172  0.070031      1  00002.wav_chunk3  \n",
       "7  116.887366  53.195553  0.068936  0.061652      1  00002.wav_chunk4  \n",
       "8   84.149052   7.553484  0.118167  0.060897      0  00003.wav_chunk1  \n",
       "9  111.379344  81.207328  0.117293  0.065956      0  00003.wav_chunk2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert feature matrix (X) into a DataFrame for better readability\n",
    "feature_columns = [f\"MFCC_{i+1}\" for i in range(13)] + [\"Pitch_Mean\", \"Pitch_Std\", \"RMS\", \"ZCR\"]\n",
    "features_df = pd.DataFrame(X, columns=feature_columns)\n",
    "\n",
    "# Add corresponding labels for better context\n",
    "features_df[\"Label\"] = y\n",
    "features_df[\"File_ID\"] = chunks_df['Chunk ID']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First 10 rows of the extracted features:\")\n",
    "display(features_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (252, 17)\n",
      "Validation set size: (84, 17)\n",
      "Test set size: (84, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train-validation and test sets (80% train-validation, 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Further split the train-validation set into training and validation sets (75% train, 25% validation of train-validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42\n",
    ")\n",
    "\n",
    "# Output shapes\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have 420 chunks:\n",
    "Training set size: 60%×420=252\n",
    "Validation set size: 20%×420=84\n",
    "Test set size: 20%×420=84\n",
    "\n",
    "Final Distribution:\n",
    "After the second split, the proportions of the original dataset are:\n",
    "Training Set: 80%×0.75=60%\n",
    "Validation Set: 80%×0.25=20%\n",
    "Test Set: 20%\n",
    "This matches the common practice of splitting datasets into 60% training, 20% validation, and 20% testing.\n",
    "\n",
    "Why Not Split Directly into 60-20-20?\n",
    "If you split directly into 60% training, 20% validation, and 20% testing, you lose flexibility to use cross-validation or other techniques on the training-validation set.\n",
    "By splitting into 80% training-validation and 20% testing first, you can adjust the train-validation ratio later without impacting the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratifying y during train-validation-test splits ensures that the proportion of classes (e.g., true_story and deceptive_story) is maintained across all subsets of the data. Here’s why this is important:\n",
    "\n",
    "1. Maintain Class Balance\n",
    "If the dataset is imbalanced (e.g., 70% true_story and 30% deceptive_story), random splitting without stratification might lead to subsets with unequal distributions, such as:\n",
    "\n",
    "Training set: 80% true_story and 20% deceptive_story\n",
    "Validation set: 90% true_story and 10% deceptive_story\n",
    "Test set: 50% true_story and 50% deceptive_story\n",
    "This imbalance can skew the model's performance metrics because the model might:\n",
    "\n",
    "Overfit to the majority class in the training set.\n",
    "Face challenges in evaluating minority class performance in the validation or test set.\n",
    "By stratifying y, the class proportions are preserved in all subsets.\n",
    "\n",
    "2. Reliable Model Evaluation\n",
    "Stratification ensures the validation and test sets are representative of the entire dataset, leading to:\n",
    "More reliable evaluation of model performance.\n",
    "Fair comparison of models during hyperparameter tuning.\n",
    "3. Reduce Variance in Results\n",
    "Without stratification, results may vary significantly with different random splits because the class distributions can vary across subsets.\n",
    "Stratification minimizes this variance, making the splits more stable and reproducible.\n",
    "\n",
    "Conclusion\n",
    "Stratifying y helps maintain class balance across subsets, making the model training and evaluation more consistent and reliable, especially in datasets with imbalanced class distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training Data Shape: (252, 17)\n",
      "Normalized Validation Data Shape: (84, 17)\n",
      "Normalized Test Data Shape: (84, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "# Use the scaler to transform validation and test data\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Print the shapes of the normalized datasets\n",
    "print(f\"Normalized Training Data Shape: {X_train_normalized.shape}\")\n",
    "print(f\"Normalized Validation Data Shape: {X_val_normalized.shape}\")\n",
    "print(f\"Normalized Test Data Shape: {X_test_normalized.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (Linear Kernel) Validation Accuracy: 0.6310, F1 Score: 0.6667\n",
      "SVM (RBF Kernel) Validation Accuracy: 0.8452, F1 Score: 0.8506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "svm_linear.fit(X_train_normalized, y_train)\n",
    "y_val_pred_linear = svm_linear.predict(X_val_normalized)\n",
    "linear_val_acc = accuracy_score(y_val, y_val_pred_linear)\n",
    "linear_val_f1 = f1_score(y_val, y_val_pred_linear)\n",
    "print(f\"SVM (Linear Kernel) Validation Accuracy: {linear_val_acc:.4f}, F1 Score: {linear_val_f1:.4f}\")\n",
    "\n",
    "# SVM with rbf kernel\n",
    "svm_rbf = SVC(C=1, gamma='scale', random_state=42, probability=True)\n",
    "svm_rbf.fit(X_train_normalized, y_train)\n",
    "y_val_pred_rbf = svm_rbf.predict(X_val_normalized)\n",
    "rbf_val_acc = accuracy_score(y_val, y_val_pred_rbf)\n",
    "rbf_val_f1 = f1_score(y_val, y_val_pred_rbf)\n",
    "print(f\"SVM (RBF Kernel) Validation Accuracy: {rbf_val_acc:.4f}, F1 Score: {rbf_val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (Linear Kernel) Cross-Validation Accuracy Scores: [0.6862745098039216, 0.5882352941176471, 0.66, 0.54, 0.62]\n",
      "SVM (Linear Kernel) Mean Accuracy: 0.6189019607843138\n",
      "SVM (Linear Kernel) Cross-Validation F1 Scores: [0.7241379310344828, 0.6181818181818182, 0.7017543859649122, 0.5660377358490566, 0.6415094339622641]\n",
      "SVM (Linear Kernel) Mean F1 Score: 0.6503242609985067\n",
      "\n",
      "SVM (RBF Kernel) Cross-Validation Accuracy Scores: [0.8431372549019608, 0.803921568627451, 0.86, 0.74, 0.72]\n",
      "SVM (RBF Kernel) Mean Accuracy: 0.7934117647058823\n",
      "SVM (RBF Kernel) Cross-Validation F1 Scores: [0.8571428571428571, 0.8214285714285714, 0.8679245283018868, 0.7636363636363637, 0.7586206896551724]\n",
      "SVM (RBF Kernel) Mean F1 Score: 0.8137506020329702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear = SVC(kernel='linear', C=1, probability=True, random_state=42)\n",
    "linear_acc_scores = []\n",
    "linear_f1_scores = []\n",
    "\n",
    "# Cross-validation for linear kernel\n",
    "for train_idx, val_idx in cv.split(X_train_normalized, y_train):\n",
    "    X_train_fold, X_val_fold = X_train_normalized[train_idx], X_train_normalized[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    svm_linear.fit(X_train_fold, y_train_fold)\n",
    "    y_val_pred = svm_linear.predict(X_val_fold)\n",
    "    linear_acc_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    linear_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "svm_linear_mean_acc = sum(linear_acc_scores) / len(linear_acc_scores)\n",
    "svm_linear_mean_f1 = sum(linear_f1_scores) / len (linear_f1_scores)\n",
    "\n",
    "\n",
    "# SVM with RBF kernel\n",
    "svm_rbf = SVC(C=1, gamma='scale', probability=True, random_state=42)\n",
    "rbf_acc_scores = []\n",
    "rbf_f1_scores = []\n",
    "\n",
    "# Cross-validation for RBF kernel\n",
    "for train_idx, val_idx in cv.split(X_train_normalized, y_train):\n",
    "    X_train_fold, X_val_fold = X_train_normalized[train_idx], X_train_normalized[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    svm_rbf.fit(X_train_fold, y_train_fold)\n",
    "    y_val_pred = svm_rbf.predict(X_val_fold)\n",
    "    rbf_acc_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    rbf_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "svm_rbf_mean_acc = sum (rbf_acc_scores) / len(rbf_acc_scores)\n",
    "svm_rbf_mean_f1 = sum (rbf_f1_scores) / len (rbf_f1_scores) \n",
    "\n",
    "# Print the results\n",
    "print(\"SVM (Linear Kernel) Cross-Validation Accuracy Scores:\", linear_acc_scores)\n",
    "print(\"SVM (Linear Kernel) Mean Accuracy:\", svm_linear_mean_acc)\n",
    "print(\"SVM (Linear Kernel) Cross-Validation F1 Scores:\", linear_f1_scores)\n",
    "print(\"SVM (Linear Kernel) Mean F1 Score:\", svm_linear_mean_f1)\n",
    "\n",
    "print(\"\\nSVM (RBF Kernel) Cross-Validation Accuracy Scores:\", rbf_acc_scores)\n",
    "print(\"SVM (RBF Kernel) Mean Accuracy:\", svm_rbf_mean_acc)\n",
    "print(\"SVM (RBF Kernel) Cross-Validation F1 Scores:\", rbf_f1_scores)\n",
    "print(\"SVM (RBF Kernel) Mean F1 Score:\", svm_rbf_mean_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.6548\n",
      "Logistic Regression Training F1 Score: 0.6836\n",
      "Logistic Regression Validation Accuracy: 0.5952\n",
      "Logistic Regression Validation F1 Score: 0.6304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_train_pred = log_reg.predict(X_train_normalized)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"Logistic Regression Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Logistic Regression Training F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred = log_reg.predict(X_val_normalized)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "print(f\"Logistic Regression Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Logistic Regression Validation F1 Score: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Accuracy Scores: [0.6666666666666666, 0.6274509803921569, 0.62, 0.54, 0.6]\n",
      "Mean Accuracy: 0.6108\n",
      "Logistic Regression Cross-Validation F1 Scores: [0.7017543859649122, 0.6545454545454545, 0.6666666666666666, 0.5818181818181818, 0.6153846153846154]\n",
      "Mean F1 Score: 0.6440\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "log_reg_acc_scores = []\n",
    "log_reg_f1_scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X_train_normalized, y_train):\n",
    "    X_train_fold, X_val_fold = X_train_normalized[train_idx], X_train_normalized[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    log_reg.fit(X_train_fold, y_train_fold)\n",
    "    y_val_pred = log_reg.predict(X_val_fold)\n",
    "    log_reg_acc_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    log_reg_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Print results\n",
    "print(f\"Logistic Regression Cross-Validation Accuracy Scores: {log_reg_acc_scores}\")\n",
    "print(f\"Mean Accuracy: {sum(log_reg_acc_scores) / len(log_reg_acc_scores):.4f}\")\n",
    "print(f\"Logistic Regression Cross-Validation F1 Scores: {log_reg_f1_scores}\")\n",
    "print(f\"Mean F1 Score: {sum(log_reg_f1_scores) / len(log_reg_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Accuracy: 0.9841\n",
      "Decision Tree Training F1 Score: 0.9847\n",
      "Decision Tree Validation Accuracy: 0.7857\n",
      "Decision Tree Validation F1 Score: 0.7907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_train_pred = dt_model.predict(X_train_normalized)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"Decision Tree Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Decision Tree Training F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred = dt_model.predict(X_val_normalized)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "print(f\"Decision Tree Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Decision Tree Validation F1 Score: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best max_depth: 10\n",
      "Best Accuracy Score: 0.7222745098039216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'max_depth': [2, 3, 5, 10, 15, 20, None]}\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Best depth and score\n",
    "print(f\"Best max_depth: {grid_search.best_params_['max_depth']}\")\n",
    "print(f\"Best Accuracy Score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 2, Validation Accuracy: 0.6429, F1 Score: 0.6154\n",
      "Max Depth: 3, Validation Accuracy: 0.6548, F1 Score: 0.5915\n",
      "Max Depth: 5, Validation Accuracy: 0.7262, F1 Score: 0.7089\n",
      "Max Depth: 10, Validation Accuracy: 0.7857, F1 Score: 0.7907\n",
      "Max Depth: 15, Validation Accuracy: 0.7619, F1 Score: 0.7561\n",
      "Max Depth: 20, Validation Accuracy: 0.7619, F1 Score: 0.7561\n",
      "Max Depth: None, Validation Accuracy: 0.7619, F1 Score: 0.7561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for depth in [2, 3, 5, 10, 15, 20, None]:\n",
    "    dt_model = DecisionTreeClassifier(random_state=42, max_depth=depth)\n",
    "    dt_model.fit(X_train_normalized, y_train)\n",
    "    y_val_pred = dt_model.predict(X_val_normalized)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    print(f\"Max Depth: {depth}, Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Cross-Validation Accuracy Scores: [0.6666666666666666, 0.6470588235294118, 0.72, 0.64, 0.66]\n",
      "Mean Accuracy: 0.6667\n",
      "Decision Tree Cross-Validation F1 Scores: [0.6222222222222222, 0.64, 0.72, 0.5714285714285714, 0.6792452830188679]\n",
      "Mean F1 Score: 0.6466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize model\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=5)  # Adjust max_depth as needed\n",
    "\n",
    "# Cross-validation\n",
    "dt_acc_scores = []\n",
    "dt_f1_scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X_train_normalized, y_train):\n",
    "    X_train_fold, X_val_fold = X_train_normalized[train_idx], X_train_normalized[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    dt_model.fit(X_train_fold, y_train_fold)\n",
    "    y_val_pred = dt_model.predict(X_val_fold)\n",
    "    dt_acc_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    dt_f1_scores.append(f1_score(y_val_fold, y_val_pred))\n",
    "\n",
    "# Print results\n",
    "print(f\"Decision Tree Cross-Validation Accuracy Scores: {dt_acc_scores}\")\n",
    "print(f\"Mean Accuracy: {sum(dt_acc_scores) / len(dt_acc_scores):.4f}\")\n",
    "print(f\"Decision Tree Cross-Validation F1 Scores: {dt_f1_scores}\")\n",
    "print(f\"Mean F1 Score: {sum(dt_f1_scores) / len(dt_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (RBF Kernel) Validation Accuracy: 0.8452, F1 Score: 0.8506\n",
      "Logistic Regression Validation Accuracy: 0.5952, F1 Score: 0.6304\n",
      "Decision Tree Validation Accuracy: 0.7857, F1 Score: 0.7907\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"SVM (RBF Kernel)\": svm_rbf,\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Decision Tree\": dt_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_normalized, y_train)\n",
    "    y_val_pred = model.predict(X_val_normalized)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    print(f\"{name} Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "\n",
      "SVM (Linear Kernel):\n",
      "  Mean Accuracy: 0.6189\n",
      "  Mean F1 Score: 0.6503\n",
      "\n",
      "SVM (RBF Kernel):\n",
      "  Mean Accuracy: 0.7934\n",
      "  Mean F1 Score: 0.8138\n",
      "\n",
      "Logistic Regression:\n",
      "  Mean Accuracy: 0.6108\n",
      "  Mean F1 Score: 0.6440\n",
      "\n",
      "Decision Tree:\n",
      "  Mean Accuracy: 0.6667\n",
      "  Mean F1 Score: 0.6466\n"
     ]
    }
   ],
   "source": [
    "# Results dictionary for easy comparison\n",
    "model_results = {\n",
    "    \"SVM (Linear Kernel)\": {\n",
    "        \"Mean Accuracy\": svm_linear_mean_acc,\n",
    "        \"Mean F1 Score\": svm_linear_mean_f1\n",
    "    },\n",
    "    \"SVM (RBF Kernel)\": {\n",
    "        \"Mean Accuracy\": svm_rbf_mean_acc,\n",
    "        \"Mean F1 Score\": svm_rbf_mean_f1\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"Mean Accuracy\": sum(log_reg_acc_scores) / len(log_reg_acc_scores),\n",
    "        \"Mean F1 Score\": sum(log_reg_f1_scores) / len(log_reg_f1_scores)\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"Mean Accuracy\": sum(dt_acc_scores) / len(dt_acc_scores),\n",
    "        \"Mean F1 Score\": sum(dt_f1_scores) / len(dt_f1_scores)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance Comparison:\")\n",
    "for model, metrics in model_results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting Validation Accuracy: 0.8214\n",
      "Majority Voting Validation F1 Score: 0.8101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize individual models\n",
    "svm_rbf = SVC(kernel='rbf', C=1, gamma='scale', probability=True, random_state=42)\n",
    "decision_tree = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "# Train individual models\n",
    "svm_rbf.fit(X_train_normalized, y_train)\n",
    "decision_tree.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Get predictions from individual models\n",
    "svm_preds = svm_rbf.predict(X_val_normalized)\n",
    "dt_preds = decision_tree.predict(X_val_normalized)\n",
    "\n",
    "# Combine predictions into an array\n",
    "all_preds = np.array([svm_preds, dt_preds])\n",
    "\n",
    "# Perform majority voting\n",
    "majority_votes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_preds)\n",
    "\n",
    "# Evaluate the majority voting ensemble\n",
    "val_acc_majority = accuracy_score(y_val, majority_votes)\n",
    "val_f1_majority = f1_score(y_val, majority_votes)\n",
    "\n",
    "print(f\"Majority Voting Validation Accuracy: {val_acc_majority:.4f}\")\n",
    "print(f\"Majority Voting Validation F1 Score: {val_f1_majority:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting Training Accuracy: 0.9683\n",
      "Majority Voting Training F1 Score: 0.9685\n",
      "Majority Voting Validation Accuracy: 0.8214\n",
      "Majority Voting Validation F1 Score: 0.8101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Majority voting for the training set\n",
    "svm_train_preds = svm_rbf.predict(X_train_normalized)\n",
    "dt_train_preds = decision_tree.predict(X_train_normalized)\n",
    "\n",
    "# Combine predictions\n",
    "all_train_preds = np.array([svm_train_preds, dt_train_preds])\n",
    "\n",
    "# Perform majority voting for training\n",
    "majority_votes_train = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_train_preds)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_acc_majority = accuracy_score(y_train, majority_votes_train)\n",
    "train_f1_majority = f1_score(y_train, majority_votes_train)\n",
    "\n",
    "print(f\"Majority Voting Training Accuracy: {train_acc_majority:.4f}\")\n",
    "print(f\"Majority Voting Training F1 Score: {train_f1_majority:.4f}\")\n",
    "\n",
    "# Majority voting for the validation set\n",
    "svm_val_preds = svm_rbf.predict(X_val_normalized)\n",
    "dt_val_preds = decision_tree.predict(X_val_normalized)\n",
    "\n",
    "# Combine predictions\n",
    "all_val_preds = np.array([svm_val_preds, dt_val_preds])\n",
    "\n",
    "# Perform majority voting for validation\n",
    "majority_votes_val = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_val_preds)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_acc_majority = accuracy_score(y_val, majority_votes_val)\n",
    "val_f1_majority = f1_score(y_val, majority_votes_val)\n",
    "\n",
    "print(f\"Majority Voting Validation Accuracy: {val_acc_majority:.4f}\")\n",
    "print(f\"Majority Voting Validation F1 Score: {val_f1_majority:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM (RBF Kernel)\n",
    "svm_rbf.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Train Decision Tree\n",
    "decision_tree.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg.fit(X_train_normalized, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting Training Accuracy: 0.9444\n",
      "Majority Voting Training F1 Score: 0.9474\n",
      "Majority Voting Validation Accuracy: 0.7976\n",
      "Majority Voting Validation F1 Score: 0.8046\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Predictions on the training set\n",
    "svm_train_preds = svm_rbf.predict(X_train_normalized)\n",
    "dt_train_preds = decision_tree.predict(X_train_normalized)\n",
    "lr_train_preds = log_reg.predict(X_train_normalized)\n",
    "\n",
    "# Combine training predictions into an array\n",
    "all_train_preds = np.array([svm_train_preds, dt_train_preds, lr_train_preds])\n",
    "\n",
    "# Perform majority voting for training\n",
    "majority_votes_train = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_train_preds)\n",
    "\n",
    "# Evaluate majority voting ensemble on training data\n",
    "train_acc_majority = accuracy_score(y_train, majority_votes_train)\n",
    "train_f1_majority = f1_score(y_train, majority_votes_train)\n",
    "\n",
    "print(f\"Majority Voting Training Accuracy: {train_acc_majority:.4f}\")\n",
    "print(f\"Majority Voting Training F1 Score: {train_f1_majority:.4f}\")\n",
    "\n",
    "# Predictions on the validation set\n",
    "svm_val_preds = svm_rbf.predict(X_val_normalized)\n",
    "dt_val_preds = decision_tree.predict(X_val_normalized)\n",
    "lr_val_preds = log_reg.predict(X_val_normalized)\n",
    "\n",
    "# Combine validation predictions into an array\n",
    "all_val_preds = np.array([svm_val_preds, dt_val_preds, lr_val_preds])\n",
    "\n",
    "# Perform majority voting for validation\n",
    "majority_votes_val = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_val_preds)\n",
    "\n",
    "# Evaluate majority voting ensemble on validation data\n",
    "val_acc_majority = accuracy_score(y_val, majority_votes_val)\n",
    "val_f1_majority = f1_score(y_val, majority_votes_val)\n",
    "\n",
    "print(f\"Majority Voting Validation Accuracy: {val_acc_majority:.4f}\")\n",
    "print(f\"Majority Voting Validation F1 Score: {val_f1_majority:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Voting Validation Accuracy: 0.7857\n",
      "Weighted Voting Validation F1 Score: 0.7955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Weighted Voting Classifier\n",
    "ensemble_weighted = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('SVM_RBF', svm_rbf),\n",
    "        ('Decision_Tree', decision_tree),\n",
    "        ('Logistic_Regression', log_reg)\n",
    "    ],\n",
    "    voting='soft',  # Use probabilities for soft voting\n",
    "    weights=[0.5, 0.4, 0.1]  # Assign weights based on individual performance\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_weighted.fit(X_train_normalized, y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_weighted = ensemble_weighted.predict(X_val_normalized)\n",
    "val_acc_weighted = accuracy_score(y_val, y_val_pred_weighted)\n",
    "val_f1_weighted = f1_score(y_val, y_val_pred_weighted)\n",
    "\n",
    "print(f\"Weighted Voting Validation Accuracy: {val_acc_weighted:.4f}\")\n",
    "print(f\"Weighted Voting Validation F1 Score: {val_f1_weighted:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
